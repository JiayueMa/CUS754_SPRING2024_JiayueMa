{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JiayueMa/CUS754_SPRING2024_JiayueMa/blob/Final_Project/codes.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQsFqj9Xm7hf"
      },
      "source": [
        "Connect with the google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPXlCE6AGSR4",
        "outputId": "48855360-023d-42e9-d407-3839993e01e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Total photos: 1943\n"
          ]
        }
      ],
      "source": [
        "#You can find the data set at https://drive.google.com/drive/folders/18ir9EY9nvsiTh3u8rKDCx7EYodoxBgLF?usp=sharing \n",
        "# or in the github folder\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "\n",
        "photo_dir = '/content/drive/MyDrive/Colab/project/target'\n",
        "\n",
        "photos = [os.path.join(photo_dir, f) for f in os.listdir(photo_dir) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "print(f\"Total photos: {len(photos)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MzV91lC7nFK0"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4PwpoFZhKYEW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from google.colab.patches import cv2_imshow\n",
        "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
        "\n",
        "# init\n",
        "model = models.mobilenet_v2(weights=MobileNet_V2_Weights.DEFAULT).eval()\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# get the features of the people\n",
        "def extract_target_features(model, loader):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        features_list = []\n",
        "        for inputs, _ in loader:\n",
        "            inputs = inputs.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            outputs = model(inputs)\n",
        "            features_list.append(outputs)\n",
        "        target_features = torch.cat(features_list).mean(0).unsqueeze(0)\n",
        "    return target_features\n",
        "\n",
        "# load the pic and features\n",
        "target_data_dir = '/content/drive/MyDrive/Colab/project'\n",
        "target_dataset = datasets.ImageFolder(root=target_data_dir, transform=transform)\n",
        "target_loader = DataLoader(target_dataset, batch_size=1, shuffle=False)\n",
        "target_features = extract_target_features(model, target_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UneVAtHknHwC"
      },
      "source": [
        "Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03Zhslrli_2Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "# operate the video\n",
        "cap = cv2.VideoCapture('/content/drive/MyDrive/Colab/videos/trump_video.mp4')\n",
        "frame_width = int(cap.get(3))\n",
        "frame_height = int(cap.get(4))\n",
        "frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "out = cv2.VideoWriter('path_to_your_output_video.mp4', cv2.VideoWriter_fourcc(*'mp4v'), frame_rate, (frame_width, frame_height))\n",
        "\n",
        "# load the machine of face detecting\n",
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if ret:\n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "\n",
        "        for (x, y, w, h) in faces:\n",
        "            face_img = frame[y:y+h, x:x+w]\n",
        "            face_img_pil = Image.fromarray(cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "            if face_img_pil.mode == 'P':\n",
        "                face_img_pil = face_img_pil.convert('RGBA')\n",
        "\n",
        "            face_tensor = transform(face_img_pil).unsqueeze(0).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "            with torch.no_grad():\n",
        "                face_features = model(face_tensor)\n",
        "                face_features = face_features.squeeze()\n",
        "\n",
        "            target_features = target_features.squeeze()\n",
        "            similarity = F.cosine_similarity(face_features.unsqueeze(0), target_features.unsqueeze(0))\n",
        "            detected = similarity.item() > 0.75\n",
        "\n",
        "            if detected:\n",
        "                cv2.circle(frame, (x + w//2, y + h//2), max(w, h)//2, (0, 255, 0), 4)\n",
        "\n",
        "        out.write(frame)\n",
        "        #cv2_imshow(frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    else:\n",
        "        break\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
